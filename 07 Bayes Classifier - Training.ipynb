{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f1f4b0",
   "metadata": {},
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0d7436ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffe56b3",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c7c41f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 2500\n",
    "\n",
    "TRAINING_DATA_FILE = \"SpamData/02_Training/train-data.txt\"\n",
    "TEST_DATA_FILE = \"SpamData/02_Training/test-data.txt\"\n",
    "\n",
    "TOKEN_SPAM_PROB_FILE = \"SpamData/03_Testing/prob-spam.txt\"\n",
    "TOKEN_HAM_PROB_FILE = \"SpamData/03_Testing/prob-nonspam.txt\"\n",
    "TOKEN_ALL_PROB_FILE = \"SpamData/03_Testing/prob-all-tokens.txt\"\n",
    "\n",
    "TEST_FEATURE_MATRIX = \"SpamData/03_Testing/test-features.txt\"\n",
    "TEST_TARGET_FILE = \"SpamData/03_Testing/test-target.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e2ea90",
   "metadata": {},
   "source": [
    "# Read and Load Features from .txt Files into NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "706232db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_train_data = np.loadtxt(TRAINING_DATA_FILE, delimiter=' ', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a0848218",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_test_data = np.loadtxt(TEST_DATA_FILE, delimiter=' ', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "071efd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of rows in training file:  265427\n",
      "Nr of rows in test file:  110522\n"
     ]
    }
   ],
   "source": [
    "print(\"Nr of rows in training file: \", sparse_train_data.shape[0])\n",
    "print(\"Nr of rows in test file: \", sparse_test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "39202c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of emails in training file:  4015\n",
      "Nr of emails in test file:  1724\n"
     ]
    }
   ],
   "source": [
    "print(\"Nr of emails in training file: \", np.unique(sparse_train_data[:, 0]).size)\n",
    "print(\"Nr of emails in test file: \", np.unique(sparse_test_data[:, 0]).size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde725cc",
   "metadata": {},
   "source": [
    "# Create empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "81ce0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty DF\n",
    "column_names = [\"DOC_ID\"] + [\"CATEGORY\"] + list(range(VOCAB_SIZE))\n",
    "index_names = np.unique(sparse_train_data[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9609f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = pd.DataFrame(index=index_names, columns=column_names)\n",
    "full_train_data.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b97831c",
   "metadata": {},
   "source": [
    "# Create a Full Matrix from a Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e8de2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_full_matrix(sparse_matrix, nr_words, doc_idx=0, word_idx=1, cat_idx=2, freq_idx=3):\n",
    "    \"\"\"\n",
    "    Form a full matrix from a sparse matrix. Return a pandas dataframe.\n",
    "    Keyword arguments:\n",
    "    sparse_matrix -- numpy array\n",
    "    nr_words -- size of the vocabulary. Total number of tokens.\n",
    "    doc_idx -- position of the document id in the sparse matrix. Default: 1st columm\n",
    "    word_idx -- position of the word id in the sparse matrix. Default: 2nd column\n",
    "    cat_idx -- position of the label (spam is 1, nonspam is 0). Default: 3rd column\n",
    "    freq_idx -- position of occurence of the word in sparse matrix. Default: 4th column\n",
    "    \"\"\"\n",
    "    column_names = [\"DOC_ID\"] + [\"CATEGORY\"] + list(range(VOCAB_SIZE))\n",
    "    doc_id_names = np.unique(sparse_train_data[:, 0])\n",
    "    full_matrix = pd.DataFrame(index=doc_id_names, columns=column_names)\n",
    "    full_matrix.fillna(value=0, inplace=True)\n",
    "    \n",
    "    for i in range(sparse_matrix.shape[0]):\n",
    "        doc_nr = sparse_matrix[i][doc_idx]\n",
    "        word_id = sparse_matrix[i][word_idx]\n",
    "        label = sparse_matrix[i][cat_idx]\n",
    "        occurrence = sparse_matrix[i][freq_idx]\n",
    "        \n",
    "        full_matrix.at[doc_nr, \"DOC_ID\"] = doc_nr\n",
    "        full_matrix.at[doc_nr, \"CATEGORY\"] = label\n",
    "        full_matrix.at[doc_nr, word_id] = occurrence\n",
    "        \n",
    "        \n",
    "    full_matrix.set_index(\"DOC_ID\", inplace=True)\n",
    "    return full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "00e727d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.78 s, sys: 91.4 ms, total: 5.87 s\n",
      "Wall time: 5.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_train_data = make_full_matrix(sparse_train_data, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6b6838d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>2498</th>\n",
       "      <th>2499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOC_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CATEGORY  0  1  2  3  4  5  6  7  8  ...  2490  2491  2492  2493  \\\n",
       "DOC_ID                                       ...                           \n",
       "0              1  2  0  0  0  0  0  0  1  0  ...     0     0     0     0   \n",
       "1              1  2  0  1  2  1  1  0  0  0  ...     0     0     0     0   \n",
       "2              1  2  0  2  0  0  3  0  0  0  ...     0     0     0     0   \n",
       "3              1  3  0  0  1  0  1  1  0  0  ...     0     0     0     0   \n",
       "4              1  0  0  0  1  2  4  2  3  1  ...     0     0     0     0   \n",
       "\n",
       "        2494  2495  2496  2497  2498  2499  \n",
       "DOC_ID                                      \n",
       "0          0     0     0     0     0     0  \n",
       "1          0     0     0     0     0     0  \n",
       "2          0     0     0     0     0     0  \n",
       "3          0     0     0     0     0     0  \n",
       "4          0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 2501 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba11881",
   "metadata": {},
   "source": [
    "# Training the Naive Bayes Model\n",
    "\n",
    "## Calculating the Probability of Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "88f70921",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_probability = full_train_data.CATEGORY.sum() / full_train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0615da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31133250311332505"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bec9806",
   "metadata": {},
   "source": [
    "# Total Number of Words / Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "57e40ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_features = full_train_data.loc[:, full_train_data.columns != \"CATEGORY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d0050628",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_lengths = full_train_features.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cbe03a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wc = email_lengths.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff8c73",
   "metadata": {},
   "source": [
    "# Number of Tokens in Spam & Ham Emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "042e27e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_lengths = email_lengths[full_train_data.CATEGORY == 0]\n",
    "ham_lengths = email_lengths[full_train_data.CATEGORY == 1]\n",
    "spam_wc = spam_lengths.sum()\n",
    "ham_wc = ham_lengths.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5146d1ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of words in spam email:  90.50488245931284\n",
      "Average number of words in ham email:  156.516\n"
     ]
    }
   ],
   "source": [
    "print(\"Average number of words in spam email: \", spam_wc/spam_lengths.shape[0])\n",
    "print(\"Average number of words in ham email: \", ham_wc/ham_lengths.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65972d8",
   "metadata": {},
   "source": [
    "# Summing the Tokens Occuring in Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b015c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4015, 2500)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8c6422b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spam_tokens = full_train_features.loc[full_train_data.CATEGORY == 1]\n",
    "summed_spam_tokens = train_spam_tokens.sum(axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "14c763d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ham_tokens = full_train_features.loc[full_train_data.CATEGORY == 0]\n",
    "summed_ham_tokens = train_ham_tokens.sum(axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "538ec5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2765, 2500)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ham_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29811d",
   "metadata": {},
   "source": [
    "## P(Token | Spam) - Probability that a Token Occurs given the Email is Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "bd8a8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tokens_spam = summed_spam_tokens / (spam_wc + VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3babe618",
   "metadata": {},
   "source": [
    "## P(Token | Ham) - Probability that a Token Occurs given the Email is Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "085552dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tokens_ham = summed_ham_tokens / (ham_wc + VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afd65c",
   "metadata": {},
   "source": [
    "# P(Token) - Probability that Token Occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "77ee45fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_tokens_all = full_train_features.sum(axis=0) / total_wc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6b51dc",
   "metadata": {},
   "source": [
    "# Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6a2fc236",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TOKEN_SPAM_PROB_FILE, prob_tokens_spam)\n",
    "np.savetxt(TOKEN_HAM_PROB_FILE, prob_tokens_ham)\n",
    "np.savetxt(TOKEN_ALL_PROB_FILE, prob_tokens_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d91236",
   "metadata": {},
   "source": [
    "# Prepare Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "53babe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110522, 4)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "384fb216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.8 s, sys: 657 ms, total: 19.5 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "full_test_data = make_full_matrix(sparse_test_data, nr_words=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "63378b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = full_test_data.loc[:, full_test_data.columns != \"CATEGORY\"]\n",
    "y_test = full_test_data.CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d8708bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(TEST_TARGET_FILE, y_test)\n",
    "np.savetxt(TEST_FEATURE_MATRIX, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e307e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbad71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafd032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f104733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
